{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Matrix Product State for MNIST\n",
    "\n",
    "This notebook will walk you through the steps for training a Matrix Product State to recognise digits in MNIST. The algorithm for training is as detailed in [Supervised Learning with Quantum-Inspired Tensor Networks](https://arxiv.org/abs/1605.05775).\n",
    "\n",
    "## Setup\n",
    "### Setting up the datasource\n",
    "Before we create the model, we must first load the MNIST data. There is a class in trMPS that makes it easy to load in MNIST data in the correct format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4e546811f05c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtrmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNISTpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpermuted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Taketomo/Documents/MPS-MNIST/trmps/MNISTpreprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspinner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "import MNISTpreprocessing\n",
    "\n",
    "permuted = False\n",
    "shuffled = True\n",
    "shrink = True\n",
    "data_source = MNISTpreprocessing.MNISTDatasource(shrink=shrink, permuted=permuted, shuffled=shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permuted controls whether the individual pixels in the dataset are permuted. (This can be used as a test to see how well the MPS picks up very long-range correlations) shuffled controls whether the individual elements in the dataset are shuffled. This shouldn't matter in the case of MPS training, especially if we feed the whole dataset in at once, but the parameter exists for the case that we feed in the dataset bit by bit. shrink controls whether the images are max-pooled before being fed into the MPS. Depending on this parameter, the image is either fed in either as 14x14 or 28x28.\n",
    "\n",
    "### Setting up the Matrix Product State\n",
    "We can then initialise a Matrix Product State as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mps import MPS\n",
    "\n",
    "d_feature = 2\n",
    "d_output = 10\n",
    "input_size = 784\n",
    "lin_reg_learning_rate = 10**(-4)\n",
    "if shrink:\n",
    "    input_size = 196\n",
    "    \n",
    "network = MPS(d_feature, d_output, input_size)\n",
    "network.prepare(data_source=data_source, learning_rate=lin_reg_learning_rate)\n",
    "# network.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters each determine the shape of the Matrix Product State. d_feature determines the size of each input, input_size determines how large the Matrix Product State, and d_output is the number of classes. Using these parameters, we can then initialise an MPS. Finally, before we do anything with the MPS, we must call its prepare method. By feeding in the data source when we prepare the MPS, the MPS' intial weights are initalised by the weights from linear regression, which leads to shorter training times. If you want to train the MPS from scratch, try commenting the current network.prepare line and uncommenting the one under it.\n",
    "\n",
    "## Training the Matrix Product State\n",
    "To train the Matrix Product State, we use an MPSOptimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from optimizer import MPSOptimizer, MPSTrainingParameters, MPSOptimizerParameters\n",
    "\n",
    "# Optimizer parameters\n",
    "max_size = 30\n",
    "min_singular_value = 0.001\n",
    "\n",
    "lr_reg = 0.0\n",
    "\n",
    "verbosity = 0\n",
    "\n",
    "optimizer_parameters = MPSOptimizerParameters(lr_reg=lr_reg,\n",
    "                                              verbosity=verbosity)\n",
    "optimizer = MPSOptimizer(network, max_size, optimizer_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max_size parameter controls how large the Matrix Product State's constituent Tensors can grow. The min singular value also controls this. These two parameters together control whether the Matrix Product State is fast (to train and to predict) but inaccurate or slow but more accurate. The faster and more inaccurate models also take up less space when saved. lr_reg controls how much the learning rate decreases as you train. Verbosity controls how much logging is printed during training. Set it to 0 to have no printing, a positive value n to have it print out the first n logs, and a negative value will have it print everything. An MPSOptimizerParameters is created with some of the parameters (There are more!) and this is then used to create an MPSOptimizer.\n",
    "\n",
    "Below, we will create an MPSTrainingParameters object in a similar way, with the parameters being quite self explanatory, and then the MPS will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rate_of_change = 5 * 10 ** (-4)\n",
    "batch_size = 2000\n",
    "n_step = 6\n",
    "\n",
    "training_parameters = MPSTrainingParameters(rate_of_change=rate_of_change)\n",
    "optimizer.train(data_source, batch_size, n_step,\n",
    "                training_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "There's lots more that can be done with Matrix Product States, and looking at the [documentation](http://trmps.readthedocs.io/en/latest/) might be a good place to start. You may have noticed that the training above took quite a long time. By using single-site DMRG as opposed to two-site DMRG as used above, by importing from singlesiteOptimizer and using SingleSiteMPSOptimizer instead of MPSOptimizer, you should see a dramatic improvement in speed. Using a cost function of squared distance, as used in the sqMPS and sqMPSOptimizer classes, included in the squaredDistanceMPS file, will also be faster. However, we find that using two-site DMRG as above, but with a larger batch size than we used in this notebook, provides more accurate results. Finally, if you want to try applying this to other datasets, the documentation provides some insights, and example scripts for how they can be used are included in the [github repo](https://github.com/TrMPS/MPS-MNIST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
